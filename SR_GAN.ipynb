{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"original.png\"\n",
    "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    #Debugging\n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "    # removing alpha channel if exists as ESRGAN does not take 4 channels\n",
    "    if image.shape[-1] == 4:\n",
    "        image = image[...,: -1]\n",
    "    # Ensure that the image dimensions are multiples of 4 (ESRGAN requires this)\n",
    "    size = (tf.convert_to_tensor(image.shape[:-1]) // 4) * 4\n",
    "    image = tf.image.crop_to_bounding_box(image, 0, 0, size[0], size[1])\n",
    "\n",
    "    # Convert the image to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # Add an extra dimension to represent the batch size\n",
    "    return tf.expand_dims(image, 0)\n",
    "  \n",
    "def save_image(image, filename):\n",
    "    \n",
    "    if not isinstance(image, Image.Image):\n",
    "        # Clip pixel values to the range [0, 255] and convert to a PIL Image\n",
    "        image = tf.clip_by_value(image, 0, 255)\n",
    "        image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "    # Save the image as a JPEG file\n",
    "    image.save(\"%s.jpg\" % filename)\n",
    "    print(\"Saved as %s.jpg\" % filename)\n",
    "\n",
    "def plot_image(image, title=\"\"):\n",
    "\n",
    "    # Convert the image tensor to a NumPy array\n",
    "    image = np.asarray(image)\n",
    "\n",
    "    # If the tensor has dimensions of size 1, squeeze the tensor\n",
    "    if image.ndim == 4 and image.shape[-1] == 1:\n",
    "        image = np.squeeze(image, axis=-1)\n",
    "    \n",
    "    # Clip pixel values to the range [0, 255] and convert to a PIL Image\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
